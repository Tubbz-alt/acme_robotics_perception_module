<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.11"/>
<title>Acme Robotics: Perception Module: /home/nrparikh/acme_robotics_perception_module/readme.md Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
  $(document).ready(initResizable);
  $(window).load(resizeHeight);
</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { init_search(); });
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">Acme Robotics: Perception Module
   &#160;<span id="projectnumber">1.0</span>
   </div>
   <div id="projectbrief">Midterm project ENPM808X</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.11 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li><a href="pages.html"><span>Related&#160;Pages</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li class="current"><a href="files.html"><span>Files</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
  <div id="navrow2" class="tabs2">
    <ul class="tablist">
      <li><a href="files.html"><span>File&#160;List</span></a></li>
      <li><a href="globals.html"><span>File&#160;Members</span></a></li>
    </ul>
  </div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(document).ready(function(){initNavTree('readme_8md.html','');});
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">/home/nrparikh/acme_robotics_perception_module/readme.md</div>  </div>
</div><!--header-->
<div class="contents">
<a href="readme_8md.html">Go to the documentation of this file.</a><div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;# Perception Module for Unmanned Aerial Vehicle </div><div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;[![Build Status](https://travis-ci.org/nr-parikh/acme_robotics_perception_module.svg?branch=master)](https://travis-ci.org/nr-parikh/acme_robotics_perception_module)</div><div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;[![Coverage Status](https://coveralls.io/repos/github/nr-parikh/acme_robotics_perception_module/badge.svg?branch=master)](https://coveralls.io/github/nr-parikh/acme_robotics_perception_module?branch=master)</div><div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160;[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://github.com/nr-parikh/acme_robotics_perception_module/blob/master/LICENSE)</div><div class="line"><a name="l00005"></a><span class="lineno">    5</span>&#160;</div><div class="line"><a name="l00006"></a><span class="lineno">    6</span>&#160;## Overview</div><div class="line"><a name="l00007"></a><span class="lineno">    7</span>&#160;</div><div class="line"><a name="l00008"></a><span class="lineno">    8</span>&#160;This is a naive perception module for the Unmanned Aerial Vehicle by Acme Robotics. The new robot being developed by Acme robotics has a downward facing camera and a front facing ultrasonic sensor. The task of the robot is to detect the boundary lines which might be there on the ground and head in the direction opposite to that of the boundary lines. It should simultaneously also monitor the incoming reading from the ultrasonic sensor and avoid obstacles if any. The developed perception module has the capability of combining the information from different sensors and decide the heading direction. The details about the module are discussed in detail here.</div><div class="line"><a name="l00009"></a><span class="lineno">    9</span>&#160;</div><div class="line"><a name="l00010"></a><span class="lineno">   10</span>&#160;The dependencies of the module are: </div><div class="line"><a name="l00011"></a><span class="lineno">   11</span>&#160;* OpenCV 3.2 or higher: To download and build the library, please follow the instructions given [here](https://www.learnopencv.com/install-opencv3-on-ubuntu/).</div><div class="line"><a name="l00012"></a><span class="lineno">   12</span>&#160;</div><div class="line"><a name="l00013"></a><span class="lineno">   13</span>&#160;## Instructions to build the module</div><div class="line"><a name="l00014"></a><span class="lineno">   14</span>&#160;Before building the module, please ensure that the dependencies are met. Please follow the instructions given below to build the module.</div><div class="line"><a name="l00015"></a><span class="lineno">   15</span>&#160;</div><div class="line"><a name="l00016"></a><span class="lineno">   16</span>&#160;```</div><div class="line"><a name="l00017"></a><span class="lineno">   17</span>&#160;$ git clone https://github.com/nr-parikh/acme_robotics_perception_module.git</div><div class="line"><a name="l00018"></a><span class="lineno">   18</span>&#160;$ cd &lt;path to repository&gt;</div><div class="line"><a name="l00019"></a><span class="lineno">   19</span>&#160;$ mkdir build</div><div class="line"><a name="l00020"></a><span class="lineno">   20</span>&#160;$ cd build</div><div class="line"><a name="l00021"></a><span class="lineno">   21</span>&#160;$ cmake ..</div><div class="line"><a name="l00022"></a><span class="lineno">   22</span>&#160;$ make</div><div class="line"><a name="l00023"></a><span class="lineno">   23</span>&#160;```</div><div class="line"><a name="l00024"></a><span class="lineno">   24</span>&#160;</div><div class="line"><a name="l00025"></a><span class="lineno">   25</span>&#160;Once the module is built correctly, to run the executable type the following command:</div><div class="line"><a name="l00026"></a><span class="lineno">   26</span>&#160;```</div><div class="line"><a name="l00027"></a><span class="lineno">   27</span>&#160;$ cd &lt;build folder of the module&gt;</div><div class="line"><a name="l00028"></a><span class="lineno">   28</span>&#160;$ ./perception_module/shell-app</div><div class="line"><a name="l00029"></a><span class="lineno">   29</span>&#160;```</div><div class="line"><a name="l00030"></a><span class="lineno">   30</span>&#160;</div><div class="line"><a name="l00031"></a><span class="lineno">   31</span>&#160;## Solo Iterative Process</div><div class="line"><a name="l00032"></a><span class="lineno">   32</span>&#160;While developing this module SIP process was followed. The link to the SIP sheet for this module is [here](https://docs.google.com/spreadsheets/d/1xeEtkg9tZwtrnPBAMPW0ByWKBNMoUEidjYDhUrIFllk/edit?usp=sharing). Please note that the legend of the code is mentioned in the sheet itself.</div><div class="line"><a name="l00033"></a><span class="lineno">   33</span>&#160;</div><div class="line"><a name="l00034"></a><span class="lineno">   34</span>&#160;Release backlog shows the improvements in the expected time to complete a certain task as the module is developed. The task backlog given detailed breakdown of time taken for each individual tasks. </div><div class="line"><a name="l00035"></a><span class="lineno">   35</span>&#160;</div><div class="line"><a name="l00036"></a><span class="lineno">   36</span>&#160;## Sensors </div><div class="line"><a name="l00037"></a><span class="lineno">   37</span>&#160;This module relies on the information incoming from two different sensors. The sensors which it uses are: </div><div class="line"><a name="l00038"></a><span class="lineno">   38</span>&#160;* RGB camera</div><div class="line"><a name="l00039"></a><span class="lineno">   39</span>&#160;* Ultrasonic Sensor</div><div class="line"><a name="l00040"></a><span class="lineno">   40</span>&#160;</div><div class="line"><a name="l00041"></a><span class="lineno">   41</span>&#160;The camera is downward facing. The position of the camera is such that it becomes easier for it to get the information of the things on the ground. The module creates a camera object which uses OpenCV&#39;s *VideoCapture* oject to reda frames of the incoming video stream. If there is a need for debugging, the camera has debugging mode. A flag can be used to toggle the debug mode. In the debug mode, the camera reads a default image provided in the *data* folder. The camera module has *is_running_* flag which indicates whether the camera is running or not. </div><div class="line"><a name="l00042"></a><span class="lineno">   42</span>&#160;</div><div class="line"><a name="l00043"></a><span class="lineno">   43</span>&#160;Ultrasonic sensor is front facing. The location is such that it can detect the obstacles in the front of the robot. In this module the readings from the sensor are simulated using pseudo-random number generator. But the logic is treats it as sensor readings and not as random numbers. The ultrasonic sensor also has *is_running_* flag which indicates whether the sensor is running or not. </div><div class="line"><a name="l00044"></a><span class="lineno">   44</span>&#160;</div><div class="line"><a name="l00045"></a><span class="lineno">   45</span>&#160;## Algorithm</div><div class="line"><a name="l00046"></a><span class="lineno">   46</span>&#160;The task at hand for robot is to be within the boundary it sees on the ground while avoiding the obstacles it sees in front of it. The main task for the perception module is to detect the caution tape in the image. To detect the tape a particular feature of the caution tape, the fact that it is yello and black, is used. Since, the colors of the tape are already known it becomes easier to detect the tape. *Camera* module pre-processes the image. Pre-processing includes finding the *inRange* pixels i.e. find the pixels which are within the range of *yellow* and *black* colors. Adding the two images will give the *blob* of tape in the image. The *perception* module then uses this pre-processed image as an input to determine the location of the tape in it. To locate the line in the given module has 2 methods: </div><div class="line"><a name="l00047"></a><span class="lineno">   47</span>&#160;</div><div class="line"><a name="l00048"></a><span class="lineno">   48</span>&#160;* First is to *Hough transforms* to find the lines. OpenCV&#39;s *Houghlines* function finds the possible lines in the image and sorts them according the number of votes. The highest voted line is the first element of the vector which can be used to find the points on that line. </div><div class="line"><a name="l00049"></a><span class="lineno">   49</span>&#160;</div><div class="line"><a name="l00050"></a><span class="lineno">   50</span>&#160;* Second method is to find the largest closed contour in the image which is probably the tape. To detect the largest contour, the simplest way is to iterate over all possible closed contours and find the largest contour based on its area. The center of the largest contour can then be found to decide the heading direction.</div><div class="line"><a name="l00051"></a><span class="lineno">   51</span>&#160;</div><div class="line"><a name="l00052"></a><span class="lineno">   52</span>&#160;Based on the method used to find the location of the tape, *control* module has different methods to compute control action. For the first method described above, the location of both the points can be used to determine whether the line is horizontal or vertical and then check if the points are located in which quadrant of the image. The angle of heading can also be calculated from the *slope* of the line. For the second method, the location of the center can be used to approximately determine the quadrant in which the line lies. This method is not good since it can locate the tape approximately. Hence, the usage of the first method is suggested and is set as default. </div><div class="line"><a name="l00053"></a><span class="lineno">   53</span>&#160;</div><div class="line"><a name="l00054"></a><span class="lineno">   54</span>&#160;The *control* module first checks the reading from the ultrasonic sensor to determine whether any obstacle is present in front of the robot or not. If it finds an obstacle it issues the command to *go back*. If no obstacles are found then it detects the tape in the image. It then locates the points and based on the location of points it generates the control action.</div><div class="line"><a name="l00055"></a><span class="lineno">   55</span>&#160;</div><div class="line"><a name="l00056"></a><span class="lineno">   56</span>&#160;## Output</div><div class="line"><a name="l00057"></a><span class="lineno">   57</span>&#160;</div><div class="line"><a name="l00058"></a><span class="lineno">   58</span>&#160;The following table shows the output for the vertically detected line in the image.</div><div class="line"><a name="l00059"></a><span class="lineno">   59</span>&#160;</div><div class="line"><a name="l00060"></a><span class="lineno">   60</span>&#160;</div><div class="line"><a name="l00061"></a><span class="lineno">   61</span>&#160;| Input Image   | Pre-processed output |</div><div class="line"><a name="l00062"></a><span class="lineno">   62</span>&#160;| ------------- | ------------- |</div><div class="line"><a name="l00063"></a><span class="lineno">   63</span>&#160;| &lt;img src=&quot;https://github.com/nr-parikh/acme_robotics_perception_module/blob/master/data/caution_tape_vertical.jpg&quot; width=&quot;405&quot;&gt;   | &lt;img src=&quot;https://github.com/nr-parikh/acme_robotics_perception_module/blob/master/data/expectedImg.jpg&quot; width=&quot;405&quot;&gt; |</div><div class="line"><a name="l00064"></a><span class="lineno">   64</span>&#160;</div><div class="line"><a name="l00065"></a><span class="lineno">   65</span>&#160;</div><div class="line"><a name="l00066"></a><span class="lineno">   66</span>&#160;| Detected Line   | Generated output action |</div><div class="line"><a name="l00067"></a><span class="lineno">   67</span>&#160;| ------------- | ------------- |</div><div class="line"><a name="l00068"></a><span class="lineno">   68</span>&#160;| &lt;img src=&quot;https://github.com/nr-parikh/acme_robotics_perception_module/blob/master/data/outputImg.jpg&quot; width=&quot;405&quot;&gt; | &lt;img src=&quot;https://github.com/nr-parikh/acme_robotics_perception_module/blob/master/data/output_1.png&quot; width=&quot;405&quot;&gt; |</div><div class="line"><a name="l00069"></a><span class="lineno">   69</span>&#160;</div><div class="line"><a name="l00070"></a><span class="lineno">   70</span>&#160;</div><div class="line"><a name="l00071"></a><span class="lineno">   71</span>&#160;The table below shows the output for the horizontally detected line in the image.</div><div class="line"><a name="l00072"></a><span class="lineno">   72</span>&#160;</div><div class="line"><a name="l00073"></a><span class="lineno">   73</span>&#160;| Input Image   | Pre-processed output |</div><div class="line"><a name="l00074"></a><span class="lineno">   74</span>&#160;| ------------- | ------------- |</div><div class="line"><a name="l00075"></a><span class="lineno">   75</span>&#160;| &lt;img src=&quot;https://github.com/nr-parikh/acme_robotics_perception_module/blob/master/data/caution_tape.jpg&quot; width=&quot;405&quot;&gt;   | &lt;img src=&quot;https://github.com/nr-parikh/acme_robotics_perception_module/blob/master/data/expectedImg2.jpg&quot; width=&quot;405&quot;&gt; |</div><div class="line"><a name="l00076"></a><span class="lineno">   76</span>&#160;</div><div class="line"><a name="l00077"></a><span class="lineno">   77</span>&#160;</div><div class="line"><a name="l00078"></a><span class="lineno">   78</span>&#160;| Detected Line   | Generated output action |</div><div class="line"><a name="l00079"></a><span class="lineno">   79</span>&#160;| ------------- | ------------- |</div><div class="line"><a name="l00080"></a><span class="lineno">   80</span>&#160;| &lt;img src=&quot;https://github.com/nr-parikh/acme_robotics_perception_module/blob/master/data/pre-process_2.jpg&quot; width=&quot;405&quot;&gt; | &lt;img src=&quot;https://github.com/nr-parikh/acme_robotics_perception_module/blob/master/data/output_2.png&quot; width=&quot;405&quot;&gt; |</div><div class="line"><a name="l00081"></a><span class="lineno">   81</span>&#160;</div></div><!-- fragment --></div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="readme_8md.html">readme.md</a></li>
    <li class="footer">Generated by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.11 </li>
  </ul>
</div>
</body>
</html>
